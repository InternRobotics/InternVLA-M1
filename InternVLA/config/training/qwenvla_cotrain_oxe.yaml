# 参数要求： 写了可以不用，但是用了就一定不能错
run_id: qwenact
run_root_dir: results/Checkpoints
seed: 42
trackers: [jsonl, wandb]
wandb_entity: jinhuiye
wandb_project: llavavla
is_debug: false

framework:
  framework_py: InternVLA-M1 # 之后注意改名字，这里确保还能 loader 之前的ckpt --> 算了直接往最后版本去？
  qwenvl: # TODO 后期不能交qwenvl 应该直接vlm
    base_vlm: ./playground/Pretrained_models/Qwen2.5-VL-3B-Instruct
    attn_implementation: flash_attention_2
    vl_hidden_dim: 2048 # TODO 应该是要去读取 内部的config
  dino:
    dino_backbone: dinov2_vits14
  layer_qformer: 
    qformer_end_layer: 37
    qformer_start_layer: 36
    num_query_tokens: 64
    input_dim: 2048 # 这里是VLM的输出维度
    ouptput_dim: 768 # 这里是 action 的输入维度 # 这里有个 规则是 ouptput_dim = action_hidden_dim； --> top2down 逻辑下不应该默认匹配，就应该人为修改
    grad_scale: 0.5 # 让梯度经过这个模块的时候进行衰减，避免破坏VLM， # 似乎会影响学习

  action_model:
    action_model_type: DiT-B
    action_hidden_dim: 768
    action_dim: 7
    use_ema: false
    future_action_window_size: 15
    past_action_window_size: 0
    repeated_diffusion_steps: 8
  
  fm_head_config:
    input_embedding_dim: 1536     # Action embedding 后的维度 48 * 32，和 DiT 的 attention_head_dim * attention_heads 对应，用于 ActionEncoder
    hidden_size: 1024     # 和 DiT 最后的 projection 对应，用于 ActionDecoder
    add_pos_embed: True
    max_seq_len: 1024
    action_dim: 7
    future_action_window_size: 15
    action_horizon: 16 # = future_action_window_size + 1 + past_action_window_size
    past_action_window_size: 0
    noise_beta_alpha: 1.5
    noise_beta_beta: 1.0
    noise_s: 0.999
    num_timestep_buckets: 1000
    num_inference_timesteps: 4
    num_target_vision_tokens: 32
    diffusion_model_cfg:    # DiT Transformers 的参数
      attention_head_dim: 48
      cross_attention_dim: 2048 # VLM 的 dim
      dropout: 0.2
      final_dropout: true
      interleave_self_attention: true
      norm_type: "ada_norm"
      num_attention_heads: 32
      num_layers: 16
      output_dim: 1024
      positional_embeddings: null

datasets:
  vlm_data:
    dataset_py: vlm_datasets
    dataformat: llava_json
    dataset_use: asv2_conversation_en,asv2_detailed_description_en,asv2_region_captioning_en,coco_internvl_longcap_en,coco_karpathy_train_567_en,coco_negative_gpt4o_en,coco_poetry_zh,coco_rem_en_zh,cocorem_exist_yorn_en,cocotextv2_en,cocotextv2_gpt4o_en,okvqa_en,refcoco_grounding_aug_en,refcoco_grounding_en,tallyqa_coco_en,toloka_grounding_aug_en,vqav2_en,vsr_en
    eval_dataset: aokvqa_cauldron_llava_format
    data_flatten: false
    base_interval: 2
    max_pixels: 50176
    min_pixels: 784
    model_max_length: 2048 # 似乎这里必须是4096， 有些相互关联的内容并没有处理到
    model_type: qwen2.5vl
    per_device_batch_size: 4

  vla_data: # TODO 首先 这个config 对 groot dataload 的干预，包括选择 obs 之类的
    dataset_py: lerobot_datasets_oxe
    data_root_dir: playground/Datasets/OXE_LEROBOT
    data_mix: bridge_rt_1 # bridge_rt_1
    action_type: delta_ee # 这个没有生效
    CoT_prompt: "Your task is {instruction}. To identify the key objects for your task. Locate their bounding boxes in [x1,y1,x2,y2] format."
    CoT_answer: bbox # 这个可以design一下， 要模仿groot modility 中去定义
    default_image_resolution: [3, 224, 224] # 还没有生效
    per_device_batch_size: 16
    load_all_data_for_training: true # 考虑如何启用 eval set
    obs: ["image_0"] # 也还没有生效
    image_size: [224,224] #todo is null keep raw size # 还没有生效

trainer:
  epochs: 100 # 决定是否使用， 他和 max_train_steps 冲突
  max_train_steps: 100000
  num_warmup_steps: 5000
  save_interval: 5000
  eval_interval: 100
  learning_rate: # you can set different lr for different modules
    base: 5e-05
    qwen_vl_interface: 1.0e-05
    action_model: 1.0e-04
  lr_scheduler_type: cosine_with_min_lr
  scheduler_specific_kwargs:
    min_lr: 5.0e-07
  freeze_modules: '' # 这里可以RE 化的 freeze 模型， print 模型, 查看组建， 如 "action_model.layer1" 代表freeze action_model 的 layer1
  loss_scale:
    vla: 1.0
    vlm: 0.1
  # pretrained_checkpoint: /mnt/petrelfs/yejinhui/Projects/llavavla/results/Checkpoints/1_need/0601_qwenact_fixqwen_32gpus_lr_1e-3_qformer_36_37/steps_100000/pytorch_model.pt
  # reload_modules: 'action_model,layer_qformer' # 警告： 这个可能会导致 模型无法收敛
  repeated_diffusion_steps: 4
  max_grad_norm: 1.0
  warmup_ratio: 0.1
  weight_decay: 0.0
  logging_frequency: 10
  gradient_clipping: 1.0
  gradient_accumulation_steps: 1

  optimizer:
    name: AdamW
    betas: [0.9, 0.95]
    eps: 1.0e-08
    weight_decay: 1.0e-08

  # 待确定的参数
  is_resume: false
  resume_epoch: null
  resume_step: null
  enable_gradient_checkpointing: true
  enable_mixed_precision_training: true
